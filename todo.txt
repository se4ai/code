# Code

# website.

divide it up like aif360

to descretize, use max-min from the parent

# Introduction
need a notation fo observables


needs intro notes on optimizers

start not tight enough yet

need little sampels for each learner

need to highlight hte mantras and the technical terms

# Ethics

need refs for

\cite{ladd1998evidence,burrell2016machine,corbett2018measure,galindo2000credit,yan2013system,chalfin2016productivity,ajit2016prediction,berk2015machine,berk2016forecasting}. 
w:w

Understanding the _neighborhood_ of a solutions is an
open and pressing issue. As [Mark Harmon](REFS#harman-2007) says:

- "In some software engineering applications, solution robustness may be as important as solution functionality. For example, it may be better to locate an area of the search space that is rich in fit solutions, rather than identifying an even better solution that is surrounded by a set of far less fit solutions.
- "Hitherto, research has tended to focus on the production of the fittest possible results. However, many application areas require solutions in a search space that may be subject to change. This makes robustness a natural second order property to which the research community could and should turn its attention.”

[^seed]: Computers don’t generate truly random numbers—they are deterministic, which means that they operate by a set of rules. You can mimic randomness by specifying a set of rules. For example, “take a number x, add 900 +x, then subtract 52.” In order for the process to start, you have to specify a starting number, x (the seed).

Also controlled here is the random number seed[^seed]. The idiom
`my =Defaults().reset()` will reset everything back to the defaults,
including the seed.  If that is not desired, just use `my=Defaults()`.



Many software engineering
problems are over-constrained and no precise solution over all
variables is achievable. In that scenario, the best we
can do explore is trade offs between potentiall competing goals.
In this approach:

-  Problem solving means
searching through the available alternatives until an acceptability threshold is met on some goals (as apposed to reaching a "best" point for all possible
goals).  
- It necessary to know how far any particular decision can be changed without compromising some
objective.

For this reason, we need solutions that speak of _regions_, not
_points_. That is,       
is a reasonable way to configure an agile prokect.

The result of such a search is a _frontier_ of solutions; i.e.
a curve of solutions within the space of different goals such that those solutions cannot be
improved for any one goal without compromising another.
 allocation of resources from which it is impossible to reallocate so as to make any one individual or preference criterion better off without making at least one individual or preference criterion worse off.
Vifredo Pareto called the se

The term satisficing, ] was introduced by Herbert A. Simon in 1956,[3] although the concept was first posited in his 1947 book Administrative Behavior.[4][5] 
Herbert Simon describes this method as _satisficing_
(a portmanteau of satisfy and suffice).
He posits that it is all we can do when 
 an optimal solution cannot be determined.


In that scenario,  the best we can do is satisficing.partial solutions based on
heuristic search methods are preferred. Solution robustness is a
major problem for such partial heuristic searches.  2 The results
of such partial heuristic search may be “brittle”; i.e. small changes
to the search results may dramatically alter the effectiveness of
the solution [31].

When offering partial solutions, it is very important to also offer insight into the space of options around the proposed solution. Such neighborhood information is very useful for managers with only partial control over their projects since it can give them confidence that even if only some of their recommendations are effected, then at least the range of outcomes is well understood.


# Code

make chops return Range(lo, hi, ystats, items=[]). then do FFT trees

add qyestuibs at end of dom (difference zitler's dom and bianry donation (see abdel)

add chop, a max depth
make better in chops a little object
  with a __call__ method
return raange with items and stats 

----



# exercises

## the homeganity assumptions of teak

givena  table of numbers, reduce k fnd nnearst neighbor. tweak the example so thatnce u get too close, variance starts going up 
again

# other

cahpte2-  ethics, insight
chaprt3 has to be case studies

# thing shta tdont seem to fit... et

- In software engineering, goals are different
- The data is different (bine;y, vriatnce, bais doe snot worka s aexpected, ore about isnight that then the data, etc).


Besides learning models from data, another important step is to use those models to propose changes that might improve the current situation. Hence whenever we generate a model (via data mining) we then try to take the next step to ask how we can use that model to optimize for user goals. 


 (Technical note: In some sense, decisions trees are a clustering algorithm. Whereas most clustering tools (k-means, mini-batch k-means, kd-trees) are unsupervised (do not reflect on the goal(s)), decision trees are supervised algorithms that reflect on the goal to divide the data.)


## Technical Notes
Formally, splitting is called discretization [webb] and recursive splitting is called iterative dichomisation [c45,cart]. 

### Algoritms

NN
Cart
linear regression
logistic regression
Naive bayes

some learners dont use ra attrbute but deroved ones:
- princple compoents, treat each row as a point in an n-dimensional space (one dimension per column) and look for  look at the average direction of data

One  way to assess a split is by the goal of the learning. For example, suppose we know that our users use a data miner to tell them where to look for bugs in the code. If our users are busy people, then they want to read the least amount of code to find the most bugs. For those users, splits are assessed via two columns $$l$$= _linesOfCode_ and
$$d$$=_defects_ and the best split is the one that maximizes $l/d$. [code, which]

Another way to assess a  split is by how much it reduces the expected delta in the variation. For example,
 
- For $n$ numeric goals $$g_1,g_2,...$$ and mean $$\overline{g}$$, the delta $$\Delta$$ can be measured using standard deviation $$\Delta=\sigma=\frac{\sum_i (g_i - \overline{g})^2}{n}$$
- For $n$ symbolic goals occurring at frequency    $$f_1,f_2,...$$, variation can be measured using entropy $$\Delta=-\sum_i p_i {\log}_2(p_i)$$ (where $$p_i= f_i/n$$)
- No matter how it is measured, the lower the delta, the less variation in the goal. 
- Suppose  the goals of  $$n_0$$ rows of data (with delta $$\Delta_0$) are split into $$n_1,n_2,_n_3$$ rows with delta $$\Delta_1,\Delta_2,\Delta_3$$, 
-  The expected delta $$\Delta'$$ after the split is $$\Delta' = n_1/n_0*\Delta_1 + n_2/n_0*\Delta_2 + n_3/n_0*\Delta_3 $$. 
- To find the best split, we search all  the columns looking for a split that results in smallest   $\Delta'$.   [code,sdiv].


Note that after splitting, we can treat all the columns as symbolic ranges. For example,
the following table would convert to:

((XXX, splitting
two numeric columns, one symbolic column, one symolic goal: find a split in the numbers that best matchs the goal. Trap; the symbolic goal splits best.))

FFD700


 use by a broader audience,

Well, SE developers using AI tools need to know about data miners, optimizers, and theorem provers.

 involved in AI?

Are you an AI engineering building software?
What do you need to know about AI?

Suppose you are AI engineering building software. 
What do AI engineers need to know about software engineering?



Suppose further you believe that you
have ethical duties  to society as a whole, and not just the current organization where you work.
What could you do about that?

The advice we offer is to say that
it is possible for engineers to educate their organizations on the benefit of
ethics using a "stick and carrot" approach:

- The "carrot" would be to observe that
the tools we call “ethical” also come with other attractive
services. For example, in this book we show that services like  explanation and monitoring and repair are part-and-parcel
of ethically-aligned-design.
That is, 
engineers can sell their organization on being ethical as a side-effect
of making their systems more comprehensible and more reliable and
more adaptable.

- The "stick" in this case is to say that it makes good business sense not to get sued.
This is an important point since an increasingly litigious
general public now  frets
that
AI
tools are not always benign or beneficial. 


This book is in two parts:

* There is the pragmatic part where we step through nine parts of standard industrial AI
practice. At each step, we offer examples on best/worst practices as well as notes on how,
pragmatically speaking, that step can be augmented with more ethics.

*  There is the also the idealized ethical part. KARROT is a reference implementation of an ethically-aligned design for data mining and optimization.
KARROT is not a replacement for current industrial tools. Rather, it is a tutorial device for demonstrating ethically-aligned design.
Its purpose of KARROT is to 
 (a) introduce a set of ethically-aligned-design concepts;
(b) show how to they might be opearationalized;
(c) offer an open source library where some parts of ethically-aligned design can be added to an existing design (if the opportunity
to do so arises);
(d)  understand the computational bottlenecks of ethically aligned design;
(e) propose research directions that could lead to better ethically align design, in the future.


Before beginning, we stress the following points. Our code is just **one way**, and not the **only way**,   to operationalize ethics. Ideally, the reader disagrees with our design choices and proposes better ones— which would be a good thing since it would mean that more people are spending more time reflecting and building systems that are more ethically-aligned.


 use by a broader audience,

Well, SE developers using AI tools need to know about data miners, optimizers, and theorem provers.

 involved in AI?

Are you an AI engineering building software?
What do you need to know about AI?

Suppose you are AI engineering building software. 
What do AI engineers need to know about software engineering?



Suppose further you believe that you
have ethical duties  to society as a whole, and not just the current organization where you work.
What could you do about that?

The advice we offer is to say that
it is possible for engineers to educate their organizations on the benefit of
ethics using a "stick and carrot" approach:

- The "carrot" would be to observe that
the tools we call “ethical” also come with other attractive
services. For example, in this book we show that services like  explanation and monitoring and repair are part-and-parcel
of ethically-aligned-design.
That is, 
engineers can sell their organization on being ethical as a side-effect
of making their systems more comprehensible and more reliable and
more adaptable.

- The "stick" in this case is to say that it makes good business sense not to get sued.
This is an important point since an increasingly litigious
general public now  frets
that
AI
tools are not always benign or beneficial. 


This book is in two parts:

* There is the pragmatic part where we step through nine parts of standard industrial AI
practice. At each step, we offer examples on best/worst practices as well as notes on how,
pragmatically speaking, that step can be augmented with more ethics.

*  There is the also the idealized ethical part. KARROT is a reference implementation of an ethically-aligned design for data mining and optimization.
KARROT is not a replacement for current industrial tools. Rather, it is a tutorial device for demonstrating ethically-aligned design.
Its purpose of KARROT is to 
 (a) introduce a set of ethically-aligned-design concepts;
(b) show how to they might be opearationalized;
(c) offer an open source library where some parts of ethically-aligned design can be added to an existing design (if the opportunity
to do so arises);
(d)  understand the computational bottlenecks of ethically aligned design;
(e) propose research directions that could lead to better ethically align design, in the future.


Before beginning, we stress the following points. Our code is just **one way**, and not the **only way**,   to operationalize ethics. Ideally, the reader disagrees with our design choices and proposes better ones— which would be a good thing since it would mean that more people are spending more time reflecting and building systems that are more ethically-aligned. 
