# Code

# website.

divide it up like aif360

to descretize, use max-min from the parent

# Introduction
need a notation fo observables


needs intro notes on optimizers

start not tight enough yet

need little sampels for each learner

need to highlight hte mantras and the technical terms

# Ethics

need refs for

\cite{ladd1998evidence,burrell2016machine,corbett2018measure,galindo2000credit,yan2013system,chalfin2016productivity,ajit2016prediction,berk2015machine,berk2016forecasting}. 
w:w

Understanding the _neighborhood_ of a solutions is an
open and pressing issue. As [Mark Harmon](REFS#harman-2007) says:

- "In some software engineering applications, solution robustness may be as important as solution functionality. For example, it may be better to locate an area of the search space that is rich in fit solutions, rather than identifying an even better solution that is surrounded by a set of far less fit solutions.
- "Hitherto, research has tended to focus on the production of the fittest possible results. However, many application areas require solutions in a search space that may be subject to change. This makes robustness a natural second order property to which the research community could and should turn its attention.”

[^seed]: Computers don’t generate truly random numbers—they are deterministic, which means that they operate by a set of rules. You can mimic randomness by specifying a set of rules. For example, “take a number x, add 900 +x, then subtract 52.” In order for the process to start, you have to specify a starting number, x (the seed).

Also controlled here is the random number seed[^seed]. The idiom
`my =Defaults().reset()` will reset everything back to the defaults,
including the seed.  If that is not desired, just use `my=Defaults()`.



Many software engineering
problems are over-constrained and no precise solution over all
variables is achievable. In that scenario, the best we
can do explore is trade offs between potentiall competing goals.
In this approach:

-  Problem solving means
searching through the available alternatives until an acceptability threshold is met on some goals (as apposed to reaching a "best" point for all possible
goals).  
- It necessary to know how far any particular decision can be changed without compromising some
objective.

For this reason, we need solutions that speak of _regions_, not
_points_. That is,       
is a reasonable way to configure an agile prokect.

The result of such a search is a _frontier_ of solutions; i.e.
a curve of solutions within the space of different goals such that those solutions cannot be
improved for any one goal without compromising another.
 allocation of resources from which it is impossible to reallocate so as to make any one individual or preference criterion better off without making at least one individual or preference criterion worse off.
Vifredo Pareto called the se

The term satisficing, ] was introduced by Herbert A. Simon in 1956,[3] although the concept was first posited in his 1947 book Administrative Behavior.[4][5] 
Herbert Simon describes this method as _satisficing_
(a portmanteau of satisfy and suffice).
He posits that it is all we can do when 
 an optimal solution cannot be determined.


In that scenario,  the best we can do is satisficing.partial solutions based on
heuristic search methods are preferred. Solution robustness is a
major problem for such partial heuristic searches.  2 The results
of such partial heuristic search may be “brittle”; i.e. small changes
to the search results may dramatically alter the effectiveness of
the solution [31].

When offering partial solutions, it is very important to also offer insight into the space of options around the proposed solution. Such neighborhood information is very useful for managers with only partial control over their projects since it can give them confidence that even if only some of their recommendations are effected, then at least the range of outcomes is well understood.


# Code

make chops return Range(lo, hi, ystats, items=[]). then do FFT trees

add qyestuibs at end of dom (difference zitler's dom and bianry donation (see abdel)

add chop, a max depth
make better in chops a little object
  with a __call__ method
return raange with items and stats 

----



# exercises

## the homeganity assumptions of teak

givena  table of numbers, reduce k fnd nnearst neighbor. tweak the example so thatnce u get too close, variance starts going up 
again

# other

cahpte2-  ethics, insight
chaprt3 has to be case studies

# thing shta tdont seem to fit... et

- In software engineering, goals are different
- The data is different (bine;y, vriatnce, bais doe snot worka s aexpected, ore about isnight that then the data, etc).


Besides learning models from data, another important step is to use those models to propose changes that might improve the current situation. Hence whenever we generate a model (via data mining) we then try to take the next step to ask how we can use that model to optimize for user goals. 


 (Technical note: In some sense, decisions trees are a clustering algorithm. Whereas most clustering tools (k-means, mini-batch k-means, kd-trees) are unsupervised (do not reflect on the goal(s)), decision trees are supervised algorithms that reflect on the goal to divide the data.)


## Technical Notes
Formally, splitting is called discretization [webb] and recursive splitting is called iterative dichomisation [c45,cart]. 

### Algoritms

NN
Cart
linear regression
logistic regression
Naive bayes

some learners dont use ra attrbute but deroved ones:
- princple compoents, treat each row as a point in an n-dimensional space (one dimension per column) and look for  look at the average direction of data

One  way to assess a split is by the goal of the learning. For example, suppose we know that our users use a data miner to tell them where to look for bugs in the code. If our users are busy people, then they want to read the least amount of code to find the most bugs. For those users, splits are assessed via two columns $$l$$= _linesOfCode_ and
$$d$$=_defects_ and the best split is the one that maximizes $l/d$. [code, which]

Another way to assess a  split is by how much it reduces the expected delta in the variation. For example,
 
- For $n$ numeric goals $$g_1,g_2,...$$ and mean $$\overline{g}$$, the delta $$\Delta$$ can be measured using standard deviation $$\Delta=\sigma=\frac{\sum_i (g_i - \overline{g})^2}{n}$$
- For $n$ symbolic goals occurring at frequency    $$f_1,f_2,...$$, variation can be measured using entropy $$\Delta=-\sum_i p_i {\log}_2(p_i)$$ (where $$p_i= f_i/n$$)
- No matter how it is measured, the lower the delta, the less variation in the goal. 
- Suppose  the goals of  $$n_0$$ rows of data (with delta $$\Delta_0$) are split into $$n_1,n_2,_n_3$$ rows with delta $$\Delta_1,\Delta_2,\Delta_3$$, 
-  The expected delta $$\Delta'$$ after the split is $$\Delta' = n_1/n_0*\Delta_1 + n_2/n_0*\Delta_2 + n_3/n_0*\Delta_3 $$. 
- To find the best split, we search all  the columns looking for a split that results in smallest   $\Delta'$.   [code,sdiv].


Note that after splitting, we can treat all the columns as symbolic ranges. For example,
the following table would convert to:

((XXX, splitting
two numeric columns, one symbolic column, one symolic goal: find a split in the numbers that best matchs the goal. Trap; the symbolic goal splits best.))

FFD700


 use by a broader audience,

Well, SE developers using AI tools need to know about data miners, optimizers, and theorem provers.

 involved in AI?

Are you an AI engineering building software?
What do you need to know about AI?

Suppose you are AI engineering building software. 
What do AI engineers need to know about software engineering?



Suppose further you believe that you
have ethical duties  to society as a whole, and not just the current organization where you work.
What could you do about that?

The advice we offer is to say that
it is possible for engineers to educate their organizations on the benefit of
ethics using a "stick and carrot" approach:

- The "carrot" would be to observe that
the tools we call “ethical” also come with other attractive
services. For example, in this book we show that services like  explanation and monitoring and repair are part-and-parcel
of ethically-aligned-design.
That is, 
engineers can sell their organization on being ethical as a side-effect
of making their systems more comprehensible and more reliable and
more adaptable.

- The "stick" in this case is to say that it makes good business sense not to get sued.
This is an important point since an increasingly litigious
general public now  frets
that
AI
tools are not always benign or beneficial. 


This book is in two parts:

* There is the pragmatic part where we step through nine parts of standard industrial AI
practice. At each step, we offer examples on best/worst practices as well as notes on how,
pragmatically speaking, that step can be augmented with more ethics.

*  There is the also the idealized ethical part. KARROT is a reference implementation of an ethically-aligned design for data mining and optimization.
KARROT is not a replacement for current industrial tools. Rather, it is a tutorial device for demonstrating ethically-aligned design.
Its purpose of KARROT is to 
 (a) introduce a set of ethically-aligned-design concepts;
(b) show how to they might be opearationalized;
(c) offer an open source library where some parts of ethically-aligned design can be added to an existing design (if the opportunity
to do so arises);
(d)  understand the computational bottlenecks of ethically aligned design;
(e) propose research directions that could lead to better ethically align design, in the future.


Before beginning, we stress the following points. Our code is just **one way**, and not the **only way**,   to operationalize ethics. Ideally, the reader disagrees with our design choices and proposes better ones— which would be a good thing since it would mean that more people are spending more time reflecting and building systems that are more ethically-aligned.


 use by a broader audience,

Well, SE developers using AI tools need to know about data miners, optimizers, and theorem provers.

 involved in AI?

Are you an AI engineering building software?
What do you need to know about AI?

Suppose you are AI engineering building software. 
What do AI engineers need to know about software engineering?



Suppose further you believe that you
have ethical duties  to society as a whole, and not just the current organization where you work.
What could you do about that?

The advice we offer is to say that
it is possible for engineers to educate their organizations on the benefit of
ethics using a "stick and carrot" approach:

- The "carrot" would be to observe that
the tools we call “ethical” also come with other attractive
services. For example, in this book we show that services like  explanation and monitoring and repair are part-and-parcel
of ethically-aligned-design.
That is, 
engineers can sell their organization on being ethical as a side-effect
of making their systems more comprehensible and more reliable and
more adaptable.

- The "stick" in this case is to say that it makes good business sense not to get sued.
This is an important point since an increasingly litigious
general public now  frets
that
AI
tools are not always benign or beneficial. 


This book is in two parts:

* There is the pragmatic part where we step through nine parts of standard industrial AI
practice. At each step, we offer examples on best/worst practices as well as notes on how,
pragmatically speaking, that step can be augmented with more ethics.

*  There is the also the idealized ethical part. KARROT is a reference implementation of an ethically-aligned design for data mining and optimization.
KARROT is not a replacement for current industrial tools. Rather, it is a tutorial device for demonstrating ethically-aligned design.
Its purpose of KARROT is to 
 (a) introduce a set of ethically-aligned-design concepts;
(b) show how to they might be opearationalized;
(c) offer an open source library where some parts of ethically-aligned design can be added to an existing design (if the opportunity
to do so arises);
(d)  understand the computational bottlenecks of ethically aligned design;
(e) propose research directions that could lead to better ethically align design, in the future.


Before beginning, we stress the following points. Our code is just **one way**, and not the **only way**,   to operationalize ethics. Ideally, the reader disagrees with our design choices and proposes better ones— which would be a good thing since it would mean that more people are spending more time reflecting and building systems that are more ethically-aligned. 


## Structure of this book.

In this book we record the core concepts of SE for AI for SE, without overly complex jargon. To that end:

- We do not attempt a complete coverage of all the topics in this area. Instead, we offer some motivating examples (and references to the rest). 
- Where we can, we offer simple Python code instead of complex formulas.

Our  code makes minimal use of external libraries (e.g. no  Pandas, no Scikitlearn, etc).  There are several reasons for this.  Firstly, the internals of some of these learners are remarkably simple. So it is easy (and fun) to code them up. Secondly, software engineers need to know how to look inside software in order to debug problems, maintain the overall system, and refactor/improve the code. In our experience, many SE people do not want to look inside the machine learning black box-- which is a shame since there is so much fun to learn in there,

Thirdly, this book was partially funded by a grant exploring   ethically applied-design. That work assumes that AI software   _could be ethical_   by virtue of its underlying design patterns and algorithms.  Of course _could be ethical_ is very different to _is ethical_. Even the best design system can be maliciously or accidentally used in an unethical way. Still, the easier it is to build ethical systems, the more likely they will get created. To that end, a minimal Python implementation called KNEAD](short for "<u>K</u>now the <u>N</u>ew   <u>E</u>thically <u>A</u>ligned <u>D</u>esign")  was created to service certain high-level ethical statements. To be sure,  KNEAD is not the only way to satisfy those ethical statements, but it is intended to be (a)   a demonstrator that such a design is possible; (b) a set of design patterns and algorithms that others can quickly port into their   preferred programming tools ; and (c) identify computational bottlenecks in ethical AI that need further research. KNEAD is a minimal implementation (that tries to avoid third party libraries) since that simplifies the second and third goal.

###   Data 

The above tools are applied to data, In the following, we say a _table_ of data contains _columns_ and _rows_ .  In reality, most data does not arrive in nearly structured tables so much work is required to make it structured (and this book devoted four chapters to that structuring process).

Within structured data, each  row containing values for  some inputs plus _g_ goal(s).

- For unsupervised learning problems, there are no goals
- For multi-objective optimization problems, there are multiple goals (which may be competing with each other). 
- Optimizers seek attribute values that minimize (or, if appropriate, maximize) numeric goals
- For classification and regression problems, there is only one symbolic/numeric goal (respectively).  Algorithms for classification or regression try to predict for goal values.
- For text mining applications, there can 100,000s of inputs (one for every word in the language being studied).

### <a name=models>Learning Algorithms</a>

_Unsupervised algorithms_   group together items with similar values. Some algorithms do not _generalize_ in the sense that the models they generate contain all the rows and all the columns. For example, clustering algorithms   bunch up the data into groups of similar rows (so all the small furry   animals might appear in one cluster and anything with feathers might appear in another). In this case, the model generated by clustering algorithms are the sets of rows in different clusters.

Another kind of unsupervised learning algorithm, are _association rule learners_ that report what column values often occur together.  For example, if we look for patterns in logs of software projects from the 1980s and the 2010s, an association rule learner might report that:

```
  # rule format: IF ==> THEN
  # IF, THEN = lists of column values
  [age=old, speed=fast] ==> [language=c, os=unix]
  [application=web] ==> [os=aws] 
```

Unlike clustering algorithms, association rule learners offer some  generalization since they do not report all the rows or all the columns.

While _unsupervised algorithms_ ignore what we know about the goal,
 _supervised algorithms_ are obsessed with goals.
 Such supervised build models that can convert inputs into some output goal(s).  Some of these models  are succinct enough  to be quickly read and understood by humans; e.g.   the decision trees learnt from CART, or linear regression equations. Other models are much more complex and   their internal models are opaque to most humans; e.g. nearest neighbor methods, Naive Bayes classifiers, random forests and neural nets. 

 When used in "what to do" mode, we explore model inputs looking for ways to improve model output (and this is called  optimization). When the model is just a simple set of slopes, such optimization is very is simple (just run down the slopes). But other kinds of models are harder to optimize:

-  The model may contain a mixture of symbols and numbers  (and gradients over symbols is not defined, using traditional maths)
-  The model divides into many small regions (each with its own properties). Such models are very common in software engineering (since every "if" statement in a program divides that program into different regions with different properties).
- The model may have many competing goals; e.g. let build software with fewer defects, in less time, using less money. Optimizing for these kinds of problems means trading off and compromising different goals.
- The model may be over-constrained; i.e. it may not be hard to satisfy all the desired goals. In this case, theorem provers can be  useful.

(Aside: Later in this book we show how to define something analogous to  "run down the slopes" for models with symbols.)

 When used in "what is" mode, models take inputs and produce outputs. This is how we generate predictions. When that output is symbolic, we might call that model a classifier (e.g. Naive Bayes classifiers).
  If the output is numeric, we might call that model a regression model (and this could be generated by a linear regression algorithm that outputs an equation of the form
  <img  src="http://latex.codecogs.com/gif.latex?y(x,\beta)=\beta_0+\beta_1x_1+\beta_2x_2+..." border="0"/>.  

 Note that some models can offer both kinds of outputs. Nearest neighbor methods make conclusions using the _k_ nearest-neighbors. When those neighbors have symbolic/numeric goals, we can predict using the mode/mean of those goals (the mean of _n_ numbers is their sum divided by _n_; the mode of a set of symbols is its most frequent symbol so the mode character in 'software engineering' is 'e').  Note that finding these neighbors can be very slow. Hence, prior to prediction, clustering is applied so that we can quickly ignore most the data (i.e. the data not in the local cluster),

Also,  Linear regression equations (that predict for numeric quantities) can be used to make symbolic (binary) decisions using logistic regression. Given an equation <img  src="http://latex.codecogs.com/gif.latex?y(x,\beta)=\beta_0+\beta_1x_1+\beta_2x_2+..." border="0"/> that  predicts for some positive quantity,  then the logistic function <img src="http://latex.codecogs.com/gif.latex?y'=1/(1+e^{-y})" border="0"/> has the range
 _0 &le; y' &le; 1_. Using this, we can predicate for (say) _bad y_ when, say, 
_y' &ge; 0.5_.

As another example of models that can make both symbolic and numeric decisions, decision trees and regression trees are both trees that make predictions by running  examples down their branches. Decision trees predict for the symbols in their leaves while regression tree predict for numbers in their leaves. Both kinds of learning can be done with one recusive splitting algorithm:

- Given columns of data, plus a goal column (numeric or symbolic), find the column that best "splits" the goal. 
- Divide the rows on that split, then recurse on each split. 

For example, splitting _age_ are 120 years  divides the goal of  _heartRate_  into rows where the rate is zero (cause they are dead) and otherwise. Before doing that split, the observed heart rate has a large delta across all the rows. But after that split, the heart rate delta is reduced (particularly for _age_>120 where the variation is now zero). 

Sometimes, such splits are misleading since they hide important numeric detail. And other times, such splits are very useful since they reduce the search space. This is because concepts spread out across a very large numeric range can be made visible by condensing the large range into a few splits.  


